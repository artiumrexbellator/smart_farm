{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe35aec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "!chmod +x spark-submit.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9efa4da8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to\n",
      "      ____              __\n",
      "     / __/__  ___ _____/ /__\n",
      "    _\\ \\/ _ \\/ _ `/ __/  '_/\n",
      "   /___/ .__/\\_,_/_/ /_/\\_\\   version 2.4.5\n",
      "      /_/\n",
      "                        \n",
      "Using Scala version 2.11.12, OpenJDK 64-Bit Server VM, 1.8.0_342\n",
      "Branch HEAD\n",
      "Compiled by user centos on 2020-02-02T19:38:06Z\n",
      "Revision cee4ecbb16917fa85f02c635925e2687400aa56b\n",
      "Url https://gitbox.apache.org/repos/asf/spark.git\n",
      "Type --help for more information.\n"
     ]
    }
   ],
   "source": [
    "!spark-submit --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "91a07c6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ivy Default Cache set to: /root/.ivy2/cache\n",
      "The jars for the packages stored in: /root/.ivy2/jars\n",
      ":: loading settings :: url = jar:file:/usr/local/lib/python3.7/site-packages/pyspark/jars/ivy-2.4.0.jar!/org/apache/ivy/core/settings/ivysettings.xml\n",
      "org.apache.bahir#spark-streaming-mqtt_2.11 added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-7aec726f-74f8-45e2-9233-04f8b935407c;1.0\n",
      "\tconfs: [default]\n",
      "\tfound org.apache.bahir#spark-streaming-mqtt_2.11;2.4.0 in central\n",
      "\tfound org.eclipse.paho#org.eclipse.paho.client.mqttv3;1.1.0 in central\n",
      "\tfound org.spark-project.spark#unused;1.0.0 in central\n",
      ":: resolution report :: resolve 286ms :: artifacts dl 22ms\n",
      "\t:: modules in use:\n",
      "\torg.apache.bahir#spark-streaming-mqtt_2.11;2.4.0 from central in [default]\n",
      "\torg.eclipse.paho#org.eclipse.paho.client.mqttv3;1.1.0 from central in [default]\n",
      "\torg.spark-project.spark#unused;1.0.0 from central in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   3   |   0   |   0   |   0   ||   3   |   0   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-7aec726f-74f8-45e2-9233-04f8b935407c\n",
      "\tconfs: [default]\n",
      "\t0 artifacts copied, 3 already retrieved (0kB/8ms)\n",
      "23/01/22 12:19:24 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "23/01/22 12:19:26 INFO SparkContext: Running Spark version 2.4.5\n",
      "23/01/22 12:19:26 INFO SparkContext: Submitted application: mqtt.py\n",
      "23/01/22 12:19:26 INFO SecurityManager: Changing view acls to: root\n",
      "23/01/22 12:19:26 INFO SecurityManager: Changing modify acls to: root\n",
      "23/01/22 12:19:26 INFO SecurityManager: Changing view acls groups to: \n",
      "23/01/22 12:19:26 INFO SecurityManager: Changing modify acls groups to: \n",
      "23/01/22 12:19:26 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()\n",
      "23/01/22 12:19:26 INFO Utils: Successfully started service 'sparkDriver' on port 33639.\n",
      "23/01/22 12:19:26 INFO SparkEnv: Registering MapOutputTracker\n",
      "23/01/22 12:19:26 INFO SparkEnv: Registering BlockManagerMaster\n",
      "23/01/22 12:19:26 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information\n",
      "23/01/22 12:19:26 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up\n",
      "23/01/22 12:19:26 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-7aa3e9da-3451-413b-8417-5eed7283ed2e\n",
      "23/01/22 12:19:26 INFO MemoryStore: MemoryStore started with capacity 366.3 MB\n",
      "23/01/22 12:19:26 INFO SparkEnv: Registering OutputCommitCoordinator\n",
      "23/01/22 12:19:27 INFO Utils: Successfully started service 'SparkUI' on port 4040.\n",
      "23/01/22 12:19:27 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://6f8468547571:4040\n",
      "23/01/22 12:19:27 INFO SparkContext: Added JAR file:///root/.ivy2/jars/org.apache.bahir_spark-streaming-mqtt_2.11-2.4.0.jar at spark://6f8468547571:33639/jars/org.apache.bahir_spark-streaming-mqtt_2.11-2.4.0.jar with timestamp 1674389967532\n",
      "23/01/22 12:19:27 INFO SparkContext: Added JAR file:///root/.ivy2/jars/org.eclipse.paho_org.eclipse.paho.client.mqttv3-1.1.0.jar at spark://6f8468547571:33639/jars/org.eclipse.paho_org.eclipse.paho.client.mqttv3-1.1.0.jar with timestamp 1674389967533\n",
      "23/01/22 12:19:27 INFO SparkContext: Added JAR file:///root/.ivy2/jars/org.spark-project.spark_unused-1.0.0.jar at spark://6f8468547571:33639/jars/org.spark-project.spark_unused-1.0.0.jar with timestamp 1674389967533\n",
      "23/01/22 12:19:27 INFO SparkContext: Added file file:///root/.ivy2/jars/org.apache.bahir_spark-streaming-mqtt_2.11-2.4.0.jar at spark://6f8468547571:33639/files/org.apache.bahir_spark-streaming-mqtt_2.11-2.4.0.jar with timestamp 1674389967581\n",
      "23/01/22 12:19:27 INFO Utils: Copying /root/.ivy2/jars/org.apache.bahir_spark-streaming-mqtt_2.11-2.4.0.jar to /tmp/spark-934bb67e-f7b8-4cae-823d-a29dcd3405ef/userFiles-5944c0f7-af48-4ecf-9eef-0c8cfc632e23/org.apache.bahir_spark-streaming-mqtt_2.11-2.4.0.jar\n",
      "23/01/22 12:19:27 INFO SparkContext: Added file file:///root/.ivy2/jars/org.eclipse.paho_org.eclipse.paho.client.mqttv3-1.1.0.jar at spark://6f8468547571:33639/files/org.eclipse.paho_org.eclipse.paho.client.mqttv3-1.1.0.jar with timestamp 1674389967623\n",
      "23/01/22 12:19:27 INFO Utils: Copying /root/.ivy2/jars/org.eclipse.paho_org.eclipse.paho.client.mqttv3-1.1.0.jar to /tmp/spark-934bb67e-f7b8-4cae-823d-a29dcd3405ef/userFiles-5944c0f7-af48-4ecf-9eef-0c8cfc632e23/org.eclipse.paho_org.eclipse.paho.client.mqttv3-1.1.0.jar\n",
      "23/01/22 12:19:27 INFO SparkContext: Added file file:///root/.ivy2/jars/org.spark-project.spark_unused-1.0.0.jar at spark://6f8468547571:33639/files/org.spark-project.spark_unused-1.0.0.jar with timestamp 1674389967638\n",
      "23/01/22 12:19:27 INFO Utils: Copying /root/.ivy2/jars/org.spark-project.spark_unused-1.0.0.jar to /tmp/spark-934bb67e-f7b8-4cae-823d-a29dcd3405ef/userFiles-5944c0f7-af48-4ecf-9eef-0c8cfc632e23/org.spark-project.spark_unused-1.0.0.jar\n",
      "23/01/22 12:19:27 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://spark-master:7077...\n",
      "23/01/22 12:19:27 INFO TransportClientFactory: Successfully created connection to spark-master/172.24.0.4:7077 after 34 ms (0 ms spent in bootstraps)\n",
      "23/01/22 12:19:28 INFO StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20230122121928-0000\n",
      "23/01/22 12:19:28 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 39445.\n",
      "23/01/22 12:19:28 INFO NettyBlockTransferService: Server created on 6f8468547571:39445\n",
      "23/01/22 12:19:28 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy\n",
      "23/01/22 12:19:28 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20230122121928-0000/0 on worker-20230122103130-172.24.0.7-37703 (172.24.0.7:37703) with 1 core(s)\n",
      "23/01/22 12:19:28 INFO StandaloneSchedulerBackend: Granted executor ID app-20230122121928-0000/0 on hostPort 172.24.0.7:37703 with 1 core(s), 1024.0 MB RAM\n",
      "23/01/22 12:19:28 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20230122121928-0000/1 on worker-20230122103130-172.24.0.5-42317 (172.24.0.5:42317) with 1 core(s)\n",
      "23/01/22 12:19:28 INFO StandaloneSchedulerBackend: Granted executor ID app-20230122121928-0000/1 on hostPort 172.24.0.5:42317 with 1 core(s), 1024.0 MB RAM\n",
      "23/01/22 12:19:28 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20230122121928-0000/2 on worker-20230122103130-172.24.0.6-38917 (172.24.0.6:38917) with 1 core(s)\n",
      "23/01/22 12:19:28 INFO StandaloneSchedulerBackend: Granted executor ID app-20230122121928-0000/2 on hostPort 172.24.0.6:38917 with 1 core(s), 1024.0 MB RAM\n",
      "23/01/22 12:19:28 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 6f8468547571, 39445, None)\n",
      "23/01/22 12:19:28 INFO BlockManagerMasterEndpoint: Registering block manager 6f8468547571:39445 with 366.3 MB RAM, BlockManagerId(driver, 6f8468547571, 39445, None)\n",
      "23/01/22 12:19:28 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 6f8468547571, 39445, None)\n",
      "23/01/22 12:19:28 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 6f8468547571, 39445, None)\n",
      "23/01/22 12:19:28 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20230122121928-0000/2 is now RUNNING\n",
      "23/01/22 12:19:28 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20230122121928-0000/1 is now RUNNING\n",
      "23/01/22 12:19:28 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20230122121928-0000/0 is now RUNNING\n",
      "23/01/22 12:19:29 INFO StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0\n",
      "^C\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/workspace/notebooks/smart farm/mqtt.py\", line 107, in <module>\n",
      "    ssc.awaitTermination()\n",
      "  File \"/usr/local/lib/python3.7/site-packages/pyspark/python/lib/pyspark.zip/pyspark/streaming/context.py\", line 192, in awaitTermination\n",
      "  File \"/usr/local/lib/python3.7/site-packages/pyspark/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1255, in __call__\n",
      "  File \"/usr/local/lib/python3.7/site-packages/pyspark/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 985, in send_command\n",
      "  File \"/usr/local/lib/python3.7/site-packages/pyspark/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1152, in send_command\n",
      "  File \"/usr/local/lib/python3.7/socket.py\", line 589, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "  File \"/usr/local/lib/python3.7/site-packages/pyspark/python/lib/pyspark.zip/pyspark/context.py\", line 270, in signal_handler\n",
      "KeyboardInterrupt\n",
      "23/01/22 12:19:42 WARN ReceiverTracker: Receiver 0 exited but didn't deregister\n"
     ]
    }
   ],
   "source": [
    "!./spark-submit.sh"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
